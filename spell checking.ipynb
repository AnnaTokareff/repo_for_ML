{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В этом задании вам необходимо будет реализовать статистический Spell Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install razdel corus numpy nltk tqdm\n",
    "#!wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import razdel\n",
    "import corus\n",
    "import numpy as np\n",
    "import nltk\n",
    "import tqdm\n",
    "import scipy\n",
    "import itertools\n",
    "import collections\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данные: Корпус русских текстов для n-gram статистики --> возьмем новостный корпус с corus\n",
    "# Словарь слов русского языка (чем больше, тем лучше)\n",
    "# Предложения, которые необходимо исправить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 1:\n",
    "\n",
    "# На первом шаге коррекции наших текстов определим такие токены, которым требуется исправление.\n",
    "# Для этого проведем статистическую бинарную классификацию токенов в наших предложениях\n",
    "# (1- токен содержит опечатку, 0- токен не содержит опечатку)\n",
    "\n",
    "# Определять неправильные токены будем с помощью формулы расчета \"подозрительности\" триграмм из статьи 1975 года \n",
    "# \"Computer Detection of Typographical Errors  R. Morris, L. Cherry\". Статья приложена.\n",
    "\n",
    "# Сначала напишем формулу для получения n-gram слова. Для формулы нам нужны только биграммы и триграммы, но мы напишем\n",
    "# функцию, которая возвращает n-граммы для любого заданного n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# как --> ['как']\n",
    "# не --> []\n",
    "# шарик --> ['шар', 'ари', 'рик']\n",
    "# неправильный --> ['неп', 'епр', 'пра', 'рав', 'ави', 'вил', 'иль', 'льн', 'ьны', 'ный']\n",
    "\n",
    "def ngram(word, n):\n",
    "    ngrams=[]\n",
    "    for i in range(len(word)):\n",
    "        ngram = \"\".join(word[i:i+n])\n",
    "        if  len (ngram) < n:\n",
    "            break\n",
    "        ngrams.append(ngram)\n",
    "    return ngrams\n",
    "    \n",
    "assert ngram('неправильный', 3) == [''.join(g) for g in list(nltk.ngrams('неправильный', 3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['неп', 'епр', 'пра', 'рав', 'ави', 'вил', 'иль', 'льн', 'ьны', 'ный']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram(\"неправильный\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Логика сбора статистики такова:\n",
    "# 1) Идем по текстам корпуса новостей\n",
    "# 2) Токенизируем тексты с помощью razdel.tokenize()\n",
    "# 3) Приводим каждый токен к нижнему регистру\n",
    "# 4) Токены, которые содержат только символы кириллицы, копим в статистику \n",
    "#    (делим токен на биграмы и триграммы и копим статистику в Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Корпус русских текстов\n",
    "from corus import load_lenta\n",
    "\n",
    "path = 'lenta-ru-news.csv.gz'\n",
    "records = load_lenta(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text= str(text).lower()\n",
    "    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    text = razdel.tokenize(text)\n",
    "    text = [t.text for t in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cyrillic(word):\n",
    "    pattern = re.compile(\"^[а-яА-Я]+$\")\n",
    "    if pattern.match(word):\n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_stats = Counter()\n",
    "\n",
    "for record in tqdm.tqdm(records):\n",
    "    #TODO: на основе текстов создать статистику триграм \n",
    "    \n",
    "    tokens = clean_text(record) # Токенизируем текст\n",
    "\n",
    "    for token in tokens:\n",
    "        if not is_cyrillic(token):\n",
    "            continue\n",
    "\n",
    "        # Нижний регистр\n",
    "        #token = token.lower()\n",
    "        \n",
    "        # Получаем триграммы и биграммы\n",
    "        n_grams_3 = ngram(token, 3)\n",
    "        n_grams_2 = ngram(token, 2)\n",
    "        for g in n_grams_3:\n",
    "            ngram_stats[g] += 1\n",
    "        for g2 in n_grams_2:\n",
    "            ngram_stats[g2] += 1\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"ngrams_dict.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(ngram_stats, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ngrams_dict.json') as json_file:\n",
    "    ngram_stats = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('broken_texts.csv.gz', compression='gzip')[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'в 1996 г . плоучил звание заслуженныйй профессор харьковского государственного университета .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].iloc[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngram_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формула для расчета подозрительности триграмы (обозначается xyz) выглядит следующим образом:\n",
    "\n",
    "$$ i(T) = \\frac{1}{2}[log(xy) + log(yz)] - log(xyz) $$\n",
    "\n",
    "Если биграма или триграма отсутствует в словаре, то значение логарифма по задумке авторов сразу равно -10\n",
    "\n",
    "Эту логику лучше вынести в отдельную функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_log(g):\n",
    "    if g in ngram_stats:\n",
    "        xyz = g\n",
    "        bigram = ngram(xyz, 2)\n",
    "        xy, yz = bigram[0], bigram[1]\n",
    "        log_xy, log_yz, log_xyz = math.log(ngram_stats[xy]), math.log(ngram_stats[yz]), math.log(ngram_stats[xyz])\n",
    "        return log_xy, log_yz, log_xyz\n",
    "    else:\n",
    "        xyz = g\n",
    "        log_xyz = -10\n",
    "        bigram = ngram(xyz, 2)\n",
    "        xy, yz = bigram[0], bigram[1]\n",
    "        \n",
    "        if xy in ngram_stats:\n",
    "            log_xy = math.log(ngram_stats[xy])\n",
    "        else:\n",
    "            log_xy = -10\n",
    "\n",
    "        if yz in ngram_stats:\n",
    "            log_yz = math.log(ngram_stats[yz])\n",
    "        else:\n",
    "            log_yz = -10\n",
    "        return log_xy, log_yz, log_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соберем всё вместе\n",
    "\n",
    "def pecularity(trigram):\n",
    "    log_xy, log_yz, log_xyz = count_log(trigram)\n",
    "    return (0.5 * (log_xy + log_yz) - log_xyz)\n",
    "\n",
    "def get_scores(token):\n",
    "#    В конечном итоге скоры для одного слова должны выглядеть как-то так:\n",
    "#     {'плоучил': \n",
    "#          {'пло': 2.59,\n",
    "#           'лоу': 3.29,\n",
    "#           'оуч': 4.09,\n",
    "#           'учи': 1.56,\n",
    "#           'чил': 2.40}\n",
    "#     }\n",
    "    tokens = {}\n",
    "    trigrams = ngram(token, 3)\n",
    "    for gr in trigrams:\n",
    "        tokens[gr] = pecularity(gr)\n",
    "    return tokens\n",
    "# Если токен имеет триграмы с скорами > 4, то мы считаем, что такой токен имеет ошибку.\n",
    "# То есть его частота в нашем корпусе частот практически незначительна\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'пло': 2.598005001331824,\n",
       " 'лоу': 3.317309312349309,\n",
       " 'оуч': 4.06931248280603,\n",
       " 'учи': 1.5528543967583328,\n",
       " 'чил': 2.380220017451915}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scores(\"плоучил\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токены, в которых есть значения выше 4: пробуем восстановить\n",
    "\n",
    "# По аналогии с решением предыдущей задачи воспользуйтесь n-gram преобразованием, чтобы найти top-k ближайших кандидатов\n",
    "# для исправления токена с помощью списка слов русского языка и функции scipy.cdist \n",
    "\n",
    "# Будем использовать и униграмы, и биграмы, и триграмы для этой части задания\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Абакан', 'Абакана', 'Абакане', 'абаканец', 'Абаканом', 'абаканская', 'абаканские', 'абаканский', 'абаканским', 'абаканскими']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1532628"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Слова русского языка\n",
    "words = list(pd.read_csv('russian_words.zip', compression='zip').values.flatten())\n",
    "\n",
    "print(words[120:130])\n",
    "\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"processed\"] = df['text'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"processed\"] = df[\"processed\"].apply(lambda x: [w for w in x if is_cyrillic(w) == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_words_in_df(lst):  # соберем все триграмы для каждого текста\n",
    "    all_words={}\n",
    "    for word in lst:\n",
    "        all_words[word] = get_scores(word)\n",
    "    return(all_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"dict_of_ngrams\"] = df[\"processed\"].apply(lambda x: check_words_in_df(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'интегумент': {'инт': 2.326208970704359,\n",
       "  'нте': 2.2527588910908705,\n",
       "  'тег': 3.9023532482785424,\n",
       "  'егу': 2.8068777168581747,\n",
       "  'гум': 3.515721293036137,\n",
       "  'уме': 2.1283376349907766,\n",
       "  'мен': 1.741324122306505,\n",
       "  'ент': 1.0945030616112206},\n",
       " 'от': {},\n",
       " 'покрывало': {'пок': 2.451738030492022,\n",
       "  'окр': 2.249554292192645,\n",
       "  'кры': 1.77561686257339,\n",
       "  'рыв': 1.9456804895024558,\n",
       "  'ыва': 1.5859252328129418,\n",
       "  'вал': 1.854516300002535,\n",
       "  'ало': 2.0451141925690095},\n",
       " 'покров': {'пок': 2.451738030492022,\n",
       "  'окр': 2.249554292192645,\n",
       "  'кро': 2.945803936295226,\n",
       "  'ров': 1.5709371735628892},\n",
       " 'термин': {'тер': 1.720899212346895,\n",
       "  'ерм': 3.0340463307357055,\n",
       "  'рми': 2.695759334473074,\n",
       "  'мин': 1.9837434414451423},\n",
       " 'лужащий': {'луж': 1.4468967374930557,\n",
       "  'ужа': 2.735297150749803,\n",
       "  'жащ': 2.0722716091434545,\n",
       "  'ащи': 1.2384223915119321,\n",
       "  'щий': 2.378485230898969},\n",
       " 'в': {},\n",
       " 'биологии': {'био': 4.070465378911553,\n",
       "  'иол': 4.8574082480242495,\n",
       "  'оло': 1.7259106055839943,\n",
       "  'лог': 2.620654268653823,\n",
       "  'оги': 1.8716418996649757,\n",
       "  'гии': 3.621215983759118},\n",
       " 'для': {'для': 0.9475635209211752},\n",
       " 'обозначения': {'обо': 2.2338347199280246,\n",
       "  'боз': 5.294172936758844,\n",
       "  'озн': 2.2246112693601976,\n",
       "  'зна': 1.908646995856273,\n",
       "  'нач': 1.720242577805724,\n",
       "  'аче': 2.062706250385615,\n",
       "  'чен': 2.11713135384489,\n",
       "  'ени': 1.0667999529528913,\n",
       "  'ния': 1.1339965286326592},\n",
       " 'покрова': {'пок': 2.451738030492022,\n",
       "  'окр': 2.249554292192645,\n",
       "  'кро': 2.945803936295226,\n",
       "  'ров': 1.5709371735628892,\n",
       "  'ова': 1.1703276936091704},\n",
       " 'оболочки': {'обо': 2.2338347199280246,\n",
       "  'бол': 1.7628271109518412,\n",
       "  'оло': 1.7259106055839943,\n",
       "  'лоч': 4.999544839193359,\n",
       "  'очк': 1.461033639960986,\n",
       "  'чки': 2.9051967096205704},\n",
       " 'организма': {'орг': 1.7808150642234022,\n",
       "  'рга': 1.2156550051090527,\n",
       "  'ган': 2.2421987658779443,\n",
       "  'ани': 1.30594271664547,\n",
       "  'низ': 3.01106825075005,\n",
       "  'изм': 2.100340235429327,\n",
       "  'зма': 3.5970113874350247},\n",
       " 'или': {'или': 1.5869737330403098},\n",
       " 'его': {'его': 1.04012908314634},\n",
       " 'части': {'час': 1.253051766867797,\n",
       "  'аст': 1.651557766475083,\n",
       "  'сти': 1.479397024868934}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"dict_of_ngrams\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classification(dic):\n",
    "    typos = []\n",
    "    for k,v in dic.items():\n",
    "        for key,val in v.items():\n",
    "            if val > 4:\n",
    "                typos.append((k, key)) \n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "    return typos\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"typo\"] = df[\"dict_of_ngrams\"].apply(lambda x: binary_classification(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"classification\"] = df[\"typo\"].apply(lambda x: 1 if len(x) > 0 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed</th>\n",
       "      <th>dict_of_ngrams</th>\n",
       "      <th>typo</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>не обнаруживается различий в общем объеме серо...</td>\n",
       "      <td>[не, обнаруживается, различий, в, общем, объем...</td>\n",
       "      <td>{'не': {}, 'обнаруживается': {'обн': 1.6718591...</td>\n",
       "      <td>[(различий, чий), (пациентов, пац), (пациентов...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>интегумент ( от - покрывало , покров ) - терми...</td>\n",
       "      <td>[интегумент, от, покрывало, покров, термин, лу...</td>\n",
       "      <td>{'интегумент': {'инт': 2.326208970704359, 'нте...</td>\n",
       "      <td>[(биологии, био), (биологии, иол), (обозначени...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22 июня 2013 года решениме большинстав судей ,...</td>\n",
       "      <td>[июня, года, решениме, большинстав, судей, бик...</td>\n",
       "      <td>{'июня': {'июн': 1.3344986291917582, 'юня': 1....</td>\n",
       "      <td>[(бика, бик), (мексики, мек), (мексики, сик), ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  не обнаруживается различий в общем объеме серо...   \n",
       "1  интегумент ( от - покрывало , покров ) - терми...   \n",
       "2  22 июня 2013 года решениме большинстав судей ,...   \n",
       "\n",
       "                                           processed  \\\n",
       "0  [не, обнаруживается, различий, в, общем, объем...   \n",
       "1  [интегумент, от, покрывало, покров, термин, лу...   \n",
       "2  [июня, года, решениме, большинстав, судей, бик...   \n",
       "\n",
       "                                      dict_of_ngrams  \\\n",
       "0  {'не': {}, 'обнаруживается': {'обн': 1.6718591...   \n",
       "1  {'интегумент': {'инт': 2.326208970704359, 'нте...   \n",
       "2  {'июня': {'июн': 1.3344986291917582, 'юня': 1....   \n",
       "\n",
       "                                                typo  classification  \n",
       "0  [(различий, чий), (пациентов, пац), (пациентов...               1  \n",
       "1  [(биологии, био), (биологии, иол), (обозначени...               1  \n",
       "2  [(бика, бик), (мексики, мек), (мексики, сик), ...               1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.typo = df.typo.apply(lambda x: list(set([word[0] for word in x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                            [различий, пациентов]\n",
       "1                [обозначения, биологии, оболочки]\n",
       "2              [бика, мексики, вакантный, антонио]\n",
       "3                                               []\n",
       "4        [всесоюзного, машинная, путевая, рекпуть]\n",
       "                           ...                    \n",
       "19995                                    [румынии]\n",
       "19996                                  [кокошкино]\n",
       "19997                                  [сасовской]\n",
       "19998       [дрогобычским, архимандриту, кучерову]\n",
       "19999                [однми, лоян, восстановления]\n",
       "Name: typo, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.typo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df_with_typos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1532628x14386 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 42188115 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# имеем матрицу, где в строках слово из словаря, а столбцы - его n-граммы\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14386"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_generator():\n",
    "    for i, line in enumerate(X):\n",
    "        yield X[i].toarray()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8845299461620748"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.spatial.distance.cosine(word, next(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = x_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'биология'\n",
    "m = vectorizer.transform([word]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.56776436]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.spatial.distance.cdist(m, next(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_candidates(word, k):\n",
    "    # TODO: predict top k most similar words from russian word dictionary\n",
    "    candids = {}\n",
    "    word_vec = vectorizer.transform([word]).toarray()\n",
    "    for i, line in enumerate(X):\n",
    "        candids[words[i]] = scipy.spatial.distance.cdist(word_vec, line.toarray())\n",
    "        \n",
    "    candidates = sorted(candids.items(), key=lambda x:x[1])[:k]\n",
    "    return (candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('биология', array([[0.]])),\n",
       " ('биологи', array([[1.73205081]])),\n",
       " ('биолог', array([[2.44948974]])),\n",
       " ('биологии', array([[2.44948974]])),\n",
       " ('биологию', array([[2.44948974]])),\n",
       " ('миология', array([[2.44948974]])),\n",
       " ('биологиня', array([[2.64575131]])),\n",
       " ('бриология', array([[2.64575131]])),\n",
       " ('агиология', array([[3.]])),\n",
       " ('биолога', array([[3.]]))]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_candidates(\"биология\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Не будем исправлять весь датасет, т.к. это занимает значительное кол-во времени. Посмотрим на строку,\n",
    "# в которой точно есть очепятки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22 июня 2013 года решениме большинстав судей , бика победил по очкам непобежденного бокера из мексики , марко антонио еприбана ( 20-0 ) , и завоевал вакантный титул чемпиона мира по версии wbc .'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text              22 июня 2013 года решениме большинстав судей ,...\n",
       "processed         [июня, года, решениме, большинстав, судей, бик...\n",
       "dict_of_ngrams    {'июня': {'июн': 1.3344986291917582, 'юня': 1....\n",
       "typo                            [бика, мексики, вакантный, антонио]\n",
       "classification                                                    1\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'июня': {'июн': 1.3344986291917582, 'юня': 1.4654724793474578},\n",
       " 'года': {'год': 1.6037757492445444, 'ода': 1.4282888161243452},\n",
       " 'решениме': {'реш': 1.8989502292089568,\n",
       "  'еше': 1.3426576457733308,\n",
       "  'шен': 1.7765328934213596,\n",
       "  'ени': 1.0667999529528913,\n",
       "  'ним': 2.4018497281385667,\n",
       "  'име': 2.125640022234938},\n",
       " 'большинстав': {'бол': 1.7628271109518412,\n",
       "  'оль': 1.5120580043310508,\n",
       "  'льш': 1.6462598456934838,\n",
       "  'ьши': 1.929774006310792,\n",
       "  'шин': 2.7156156694649987,\n",
       "  'инс': 1.9388909682565156,\n",
       "  'нст': 2.835831626100598,\n",
       "  'ста': 1.3697325604490391,\n",
       "  'тав': 1.686949866090746},\n",
       " 'судей': {'суд': 0.989710884912693,\n",
       "  'уде': 2.002849116803155,\n",
       "  'дей': 2.5870419339954935},\n",
       " 'бика': {'бик': 6.311041097815426, 'ика': 1.4389247695301641},\n",
       " 'победил': {'поб': 3.942191705114862,\n",
       "  'обе': 2.088671052581212,\n",
       "  'бед': 2.890795285616184,\n",
       "  'еди': 1.85005684767264,\n",
       "  'дил': 2.6082098333446293},\n",
       " 'по': {},\n",
       " 'очкам': {'очк': 1.461033639960986,\n",
       "  'чка': 3.036883198412921,\n",
       "  'кам': 2.5925859162247598},\n",
       " 'непобежденного': {'неп': 2.870348811144078,\n",
       "  'епо': 3.2985955281222346,\n",
       "  'поб': 3.942191705114862,\n",
       "  'обе': 2.088671052581212,\n",
       "  'беж': 2.4220885896130966,\n",
       "  'ежд': 0.9762178459092539,\n",
       "  'жде': 1.9359900380134967,\n",
       "  'ден': 1.7605200947392365,\n",
       "  'енн': 1.1660852234950525,\n",
       "  'нно': 1.4663617139535123,\n",
       "  'ног': 1.7020279484664247,\n",
       "  'ого': 0.679976632513263},\n",
       " 'бокера': {'бок': 3.8965259682176967,\n",
       "  'оке': 3.329766267787459,\n",
       "  'кер': 3.5035907423048958,\n",
       "  'ера': 2.481187630373027},\n",
       " 'из': {},\n",
       " 'мексики': {'мек': 4.930242908008978,\n",
       "  'екс': 1.4412699122862396,\n",
       "  'кси': 2.728516944730009,\n",
       "  'сик': 4.690509765746322,\n",
       "  'ики': 1.9634205050900153},\n",
       " 'марко': {'мар': 2.33020020231454,\n",
       "  'арк': 2.0934027797402166,\n",
       "  'рко': 3.0142605905269804},\n",
       " 'антонио': {'ант': 2.7396569911533852,\n",
       "  'нто': 2.576071326316498,\n",
       "  'тон': 3.5626547052763833,\n",
       "  'они': 2.868624377134008,\n",
       "  'нио': 6.494785744714889},\n",
       " 'еприбана': {'епр': 3.235941759202655,\n",
       "  'при': 1.2082667582143234,\n",
       "  'риб': 2.7303553261768396,\n",
       "  'иба': 3.490698928682395,\n",
       "  'бан': 2.481115329452164,\n",
       "  'ана': 2.637776824656065},\n",
       " 'и': {},\n",
       " 'завоевал': {'зав': 2.9219182608916157,\n",
       "  'аво': 2.9064236237113477,\n",
       "  'вое': 1.821674297499003,\n",
       "  'оев': 2.6451680837852827,\n",
       "  'ева': 2.511541825227125,\n",
       "  'вал': 1.854516300002535},\n",
       " 'вакантный': {'вак': 4.836000687390786,\n",
       "  'ака': 2.9332483827356324,\n",
       "  'кан': 2.555359257099205,\n",
       "  'ант': 2.7396569911533852,\n",
       "  'нтн': 4.169444065376654,\n",
       "  'тны': 1.9877814922183283,\n",
       "  'ный': 1.1773091953866288},\n",
       " 'титул': {'тит': 2.712845034625664,\n",
       "  'иту': 2.924844626084967,\n",
       "  'тул': 3.983346434255651},\n",
       " 'чемпиона': {'чем': 2.603477141553869,\n",
       "  'емп': 2.511282015917084,\n",
       "  'мпи': 1.8594934910251961,\n",
       "  'пио': 2.3390670287859052,\n",
       "  'ион': 0.964776681490946,\n",
       "  'она': 2.1195979874384676},\n",
       " 'мира': {'мир': 1.695225971086014, 'ира': 2.4295504788828346},\n",
       " 'версии': {'вер': 1.6433058126347806,\n",
       "  'ерс': 1.9539075031406519,\n",
       "  'рси': 2.5169325954483543,\n",
       "  'сии': 1.7341399350227729}}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dict_of_ngrams.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# здесь алгоритм с n-граммами, к сожалению, не очень сработал, поэтому вручную выделим слова с ошибками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_correct = ['решениме', 'большинстав', 'боксера', 'еприбана'] # Перибана "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('решение', array([[2.64575131]])), ('решением', array([[2.82842712]]))]\n",
      "[('большинст', array([[2.44948974]])), ('большинства', array([[2.82842712]]))]\n",
      "[('боксера', array([[0.]])), ('боксер', array([[1.73205081]]))]\n",
      "[('приба', array([[3.]])), ('прибав', array([[3.46410162]]))]\n"
     ]
    }
   ],
   "source": [
    "for word in to_correct:\n",
    "    predict_candidates(word, 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# все предсказал правильно за исключением фамилии боксера (Перибан)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
