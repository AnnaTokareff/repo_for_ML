{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В этом задании вам необходимо будет реализовать статистический Spell Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install razdel corus numpy nltk tqdm\n",
    "#!wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import razdel\n",
    "import corus\n",
    "import numpy as np\n",
    "import nltk\n",
    "import tqdm\n",
    "import collections\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данные: Корпус русских текстов для n-gram статистики --> возьмем новостный корпус с corus\n",
    "# Словарь слов русского языка (чем больше, тем лучше)\n",
    "# Предложения, которые необходимо исправить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 1:\n",
    "\n",
    "# На первом шаге коррекции наших текстов определим такие токены, которым требуется исправление.\n",
    "# Для этого проведем статистическую бинарную классификацию токенов в наших предложениях\n",
    "# (1- токен содержит опечатку, 0- токен не содержит опечатку)\n",
    "\n",
    "# Определять неправильные токены будем с помощью формулы расчета \"подозрительности\" триграмм из статьи 1975 года \n",
    "# \"Computer Detection of Typographical Errors  R. Morris, L. Cherry\". Статья приложена.\n",
    "\n",
    "# Сначала напишем формулу для получения n-gram слова. Для формулы нам нужны только биграммы и триграммы, но мы напишем\n",
    "# функцию, которая возвращает n-граммы для любого заданного n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# как --> ['как']\n",
    "# не --> []\n",
    "# шарик --> ['шар', 'ари', 'рик']\n",
    "# неправильный --> ['неп', 'епр', 'пра', 'рав', 'ави', 'вил', 'иль', 'льн', 'ьны', 'ный']\n",
    "\n",
    "def ngram(word, n):\n",
    "    ngrams=[]\n",
    "    for i in range(len(word)):\n",
    "        ngram = \"\".join(word[i:i+n])\n",
    "        if  len (ngram) < n:\n",
    "            break\n",
    "        ngrams.append(ngram)\n",
    "    return ngrams\n",
    "    \n",
    "assert ngram('неправильный', 3) == [''.join(g) for g in list(nltk.ngrams('неправильный', 3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['неп', 'епр', 'пра', 'рав', 'ави', 'вил', 'иль', 'льн', 'ьны', 'ный']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram(\"неправильный\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Логика сбора статистики такова:\n",
    "# 1) Идем по текстам корпуса новостей\n",
    "# 2) Токенизируем тексты с помощью razdel.tokenize()\n",
    "# 3) Приводим каждый токен к нижнему регистру\n",
    "# 4) Токены, которые содержат только символы кириллицы, копим в статистику \n",
    "#    (делим токен на биграмы и триграммы и копим статистику в Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Корпус русских текстов\n",
    "from corus import load_lenta\n",
    "\n",
    "path = 'lenta-ru-news.csv.gz'\n",
    "records = load_lenta(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text= str(text).lower()\n",
    "    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    text = razdel.tokenize(text)\n",
    "    text = [t.text for t in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cyrillic(word):\n",
    "    pattern = re.compile(\"^[а-яА-Я]+$\")\n",
    "    if pattern.match(word):\n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_stats = Counter()\n",
    "\n",
    "for record in tqdm.tqdm(records):\n",
    "    #TODO: на основе текстов создать статистику триграм \n",
    "    \n",
    "    tokens = clean_text(record) # Токенизируем текст\n",
    "\n",
    "    for token in tokens:\n",
    "        if not is_cyrillic(token):\n",
    "            continue\n",
    "\n",
    "        # Нижний регистр\n",
    "        #token = token.lower()\n",
    "        \n",
    "        # Получаем триграммы и биграммы\n",
    "        n_grams_3 = ngram(token, 3)\n",
    "        n_grams_2 = ngram(token, 2)\n",
    "        for g in n_grams_3:\n",
    "            ngram_stats[g] += 1\n",
    "        for g2 in n_grams_2:\n",
    "            ngram_stats[g2] += 1\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"ngrams_dict.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(ngram_stats, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ngrams_dict.json') as json_file:\n",
    "    ngram_stats = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('broken_texts.csv.gz', compression='gzip')[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'в 1996 г . плоучил звание заслуженныйй профессор харьковского государственного университета .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].iloc[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngram_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формула для расчета подозрительности триграмы (обозначается xyz) выглядит следующим образом:\n",
    "\n",
    "$$ i(T) = \\frac{1}{2}[log(xy) + log(yz)] - log(xyz) $$\n",
    "\n",
    "Если биграма или триграма отсутствует в словаре, то значение логарифма по задумке авторов сразу равно -10\n",
    "\n",
    "Эту логику лучше вынести в отдельную функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_log(g):\n",
    "    if g in ngram_stats:\n",
    "        xyz = g\n",
    "        bigram = ngram(xyz, 2)\n",
    "        xy, yz = bigram[0], bigram[1]\n",
    "        log_xy, log_yz, log_xyz = math.log(ngram_stats[xy]), math.log(ngram_stats[yz]), math.log(ngram_stats[xyz])\n",
    "        return log_xy, log_yz, log_xyz\n",
    "    else:\n",
    "        xyz = g\n",
    "        log_xyz = -10\n",
    "        bigram = ngram(xyz, 2)\n",
    "        xy, yz = bigram[0], bigram[1]\n",
    "        \n",
    "        if xy in ngram_stats:\n",
    "            log_xy = math.log(ngram_stats[xy])\n",
    "        else:\n",
    "            log_xy = -10\n",
    "\n",
    "        if yz in ngram_stats:\n",
    "            log_yz = math.log(ngram_stats[yz])\n",
    "        else:\n",
    "            log_yz = -10\n",
    "        return log_xy, log_yz, log_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соберем всё вместе\n",
    "\n",
    "def pecularity(trigram):\n",
    "    log_xy, log_yz, log_xyz = count_log(trigram)\n",
    "    return (0.5 * (log_xy + log_yz) - log_xyz)\n",
    "\n",
    "def get_scores(token):\n",
    "#    В конечном итоге скоры для одного слова должны выглядеть как-то так:\n",
    "#     {'плоучил': \n",
    "#          {'пло': 2.59,\n",
    "#           'лоу': 3.29,\n",
    "#           'оуч': 4.09,\n",
    "#           'учи': 1.56,\n",
    "#           'чил': 2.40}\n",
    "#     }\n",
    "    tokens = {}\n",
    "    trigrams = ngram(token, 3)\n",
    "    for gr in trigrams:\n",
    "        tokens[gr] = pecularity(gr)\n",
    "    return tokens\n",
    "# Если токен имеет триграмы с скорами > 4, то мы считаем, что такой токен имеет ошибку.\n",
    "# То есть его частота в нашем корпусе частот практически незначительна\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'пло': 2.598005001331824,\n",
       " 'лоу': 3.317309312349309,\n",
       " 'оуч': 4.06931248280603,\n",
       " 'учи': 1.5528543967583328,\n",
       " 'чил': 2.380220017451915}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scores(\"плоучил\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токены, в которых есть значения выше 4: пробуем восстановить\n",
    "\n",
    "# По аналогии с решением предыдущей задачи воспользуйтесь n-gram преобразованием, чтобы найти top-k ближайших кандидатов\n",
    "# для исправления токена с помощью списка слов русского языка и функции scipy.cdist \n",
    "\n",
    "# Будем использовать и униграмы, и биграмы, и триграмы для этой части задания\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Абакан', 'Абакана', 'Абакане', 'абаканец', 'Абаканом', 'абаканская', 'абаканские', 'абаканский', 'абаканским', 'абаканскими']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1532628"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Слова русского языка\n",
    "words = list(pd.read_csv('russian_words.zip', compression='zip').values.flatten())\n",
    "\n",
    "print(words[120:130])\n",
    "\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"processed\"] = df['text'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"processed\"] = df[\"processed\"].apply(lambda x: [w for w in x if is_cyrillic(w) == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_words_in_df(lst):  # соберем все триграмы для каждого текста\n",
    "    all_words={}\n",
    "    for word in lst:\n",
    "        all_words[word] = get_scores(word)\n",
    "    return(all_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"dict_of_ngrams\"] = df[\"processed\"].apply(lambda x: check_words_in_df(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'интегумент': {'инт': 2.326208970704359,\n",
       "  'нте': 2.2527588910908705,\n",
       "  'тег': 3.9023532482785424,\n",
       "  'егу': 2.8068777168581747,\n",
       "  'гум': 3.515721293036137,\n",
       "  'уме': 2.1283376349907766,\n",
       "  'мен': 1.741324122306505,\n",
       "  'ент': 1.0945030616112206},\n",
       " 'от': {},\n",
       " 'покрывало': {'пок': 2.451738030492022,\n",
       "  'окр': 2.249554292192645,\n",
       "  'кры': 1.77561686257339,\n",
       "  'рыв': 1.9456804895024558,\n",
       "  'ыва': 1.5859252328129418,\n",
       "  'вал': 1.854516300002535,\n",
       "  'ало': 2.0451141925690095},\n",
       " 'покров': {'пок': 2.451738030492022,\n",
       "  'окр': 2.249554292192645,\n",
       "  'кро': 2.945803936295226,\n",
       "  'ров': 1.5709371735628892},\n",
       " 'термин': {'тер': 1.720899212346895,\n",
       "  'ерм': 3.0340463307357055,\n",
       "  'рми': 2.695759334473074,\n",
       "  'мин': 1.9837434414451423},\n",
       " 'лужащий': {'луж': 1.4468967374930557,\n",
       "  'ужа': 2.735297150749803,\n",
       "  'жащ': 2.0722716091434545,\n",
       "  'ащи': 1.2384223915119321,\n",
       "  'щий': 2.378485230898969},\n",
       " 'в': {},\n",
       " 'биологии': {'био': 4.070465378911553,\n",
       "  'иол': 4.8574082480242495,\n",
       "  'оло': 1.7259106055839943,\n",
       "  'лог': 2.620654268653823,\n",
       "  'оги': 1.8716418996649757,\n",
       "  'гии': 3.621215983759118},\n",
       " 'для': {'для': 0.9475635209211752},\n",
       " 'обозначения': {'обо': 2.2338347199280246,\n",
       "  'боз': 5.294172936758844,\n",
       "  'озн': 2.2246112693601976,\n",
       "  'зна': 1.908646995856273,\n",
       "  'нач': 1.720242577805724,\n",
       "  'аче': 2.062706250385615,\n",
       "  'чен': 2.11713135384489,\n",
       "  'ени': 1.0667999529528913,\n",
       "  'ния': 1.1339965286326592},\n",
       " 'покрова': {'пок': 2.451738030492022,\n",
       "  'окр': 2.249554292192645,\n",
       "  'кро': 2.945803936295226,\n",
       "  'ров': 1.5709371735628892,\n",
       "  'ова': 1.1703276936091704},\n",
       " 'оболочки': {'обо': 2.2338347199280246,\n",
       "  'бол': 1.7628271109518412,\n",
       "  'оло': 1.7259106055839943,\n",
       "  'лоч': 4.999544839193359,\n",
       "  'очк': 1.461033639960986,\n",
       "  'чки': 2.9051967096205704},\n",
       " 'организма': {'орг': 1.7808150642234022,\n",
       "  'рга': 1.2156550051090527,\n",
       "  'ган': 2.2421987658779443,\n",
       "  'ани': 1.30594271664547,\n",
       "  'низ': 3.01106825075005,\n",
       "  'изм': 2.100340235429327,\n",
       "  'зма': 3.5970113874350247},\n",
       " 'или': {'или': 1.5869737330403098},\n",
       " 'его': {'его': 1.04012908314634},\n",
       " 'части': {'час': 1.253051766867797,\n",
       "  'аст': 1.651557766475083,\n",
       "  'сти': 1.479397024868934}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"dict_of_ngrams\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classification(dic):\n",
    "    typos = []\n",
    "    for k,v in dic.items():\n",
    "        for key,val in v.items():\n",
    "            if val > 4:\n",
    "                typos.append((key, val)) \n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "    return typos\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"typo\"] = df[\"dict_of_ngrams\"].apply(lambda x: binary_classification(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"classification\"] = df[\"typo\"].apply(lambda x: 1 if len(x) > 0 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed</th>\n",
       "      <th>dict_of_ngrams</th>\n",
       "      <th>typo</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>не обнаруживается различий в общем объеме серо...</td>\n",
       "      <td>[не, обнаруживается, различий, в, общем, объем...</td>\n",
       "      <td>{'не': {}, 'обнаруживается': {'обн': 1.6718591...</td>\n",
       "      <td>[(чий, 4.768692534844364), (пац, 4.94659706913...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>интегумент ( от - покрывало , покров ) - терми...</td>\n",
       "      <td>[интегумент, от, покрывало, покров, термин, лу...</td>\n",
       "      <td>{'интегумент': {'инт': 2.326208970704359, 'нте...</td>\n",
       "      <td>[(био, 4.070465378911553), (иол, 4.85740824802...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22 июня 2013 года решениме большинстав судей ,...</td>\n",
       "      <td>[июня, года, решениме, большинстав, судей, бик...</td>\n",
       "      <td>{'июня': {'июн': 1.3344986291917582, 'юня': 1....</td>\n",
       "      <td>[(бик, 6.311041097815426), (мек, 4.93024290800...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  не обнаруживается различий в общем объеме серо...   \n",
       "1  интегумент ( от - покрывало , покров ) - терми...   \n",
       "2  22 июня 2013 года решениме большинстав судей ,...   \n",
       "\n",
       "                                           processed  \\\n",
       "0  [не, обнаруживается, различий, в, общем, объем...   \n",
       "1  [интегумент, от, покрывало, покров, термин, лу...   \n",
       "2  [июня, года, решениме, большинстав, судей, бик...   \n",
       "\n",
       "                                      dict_of_ngrams  \\\n",
       "0  {'не': {}, 'обнаруживается': {'обн': 1.6718591...   \n",
       "1  {'интегумент': {'инт': 2.326208970704359, 'нте...   \n",
       "2  {'июня': {'июн': 1.3344986291917582, 'юня': 1....   \n",
       "\n",
       "                                                typo  classification  \n",
       "0  [(чий, 4.768692534844364), (пац, 4.94659706913...               1  \n",
       "1  [(био, 4.070465378911553), (иол, 4.85740824802...               1  \n",
       "2  [(бик, 6.311041097815426), (мек, 4.93024290800...               1  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df_with_typos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_candidates(word, k):\n",
    "    # TODO: predict top k most similar words from russian word dictionary\n",
    "    return candidates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
