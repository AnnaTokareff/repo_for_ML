{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "vQjltCZ4brpA"
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "import numpy as np\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6gmGzGIa0cL"
   },
   "source": [
    "Вспомним, как писать бесконечные генераторы с помощью ```yield```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2Lg74Y9UH-L",
    "outputId": "7c099b47-89dd-4854-8059-004703232a80",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def num_generator():\n",
    "    i= 0\n",
    "    while True:\n",
    "        yield i\n",
    "        i += 1     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "gen = num_generator()\n",
    "print(next(gen))\n",
    "print(next(gen))\n",
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fmxR_jgXuYY"
   },
   "source": [
    "А если хочется получить сразу несколько первых элементов из генератора?\n",
    "\n",
    "**Задание** Напишите функцию-генератор, которая будет выдавать элементы до тех пор, пока не наберется нужное количество (`n`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YuEU7h3YW_E4",
    "outputId": "c36807ca-62af-4669-e86d-8ebfbe93214c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def take(generator, n):\n",
    "    try:\n",
    "        for i in range(n):\n",
    "            yield (next(generator))\n",
    "        \n",
    "    except StopIteration:\n",
    "        pass\n",
    "    \n",
    "list(take(num_generator(), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1s7TVDJaddz"
   },
   "source": [
    "**Задание** Напишите генератор, который будет выдавать только четные числа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5E0D1xdNVsxf",
    "outputId": "96b846a6-068d-4f5e-9d2e-c1487910a311"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6, 8]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def even_num_generator(num_generator):\n",
    "    while True:\n",
    "        num = next(num_generator)\n",
    "        if num % 2 == 0:\n",
    "            yield num\n",
    "\n",
    "list(take(even_num_generator(num_generator()), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppitp0YmbgqI"
   },
   "source": [
    "## N-граммная языковая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15fhnu6GtlGv",
    "outputId": "f5bb05c4-188d-4e6d-e174-f1c6e625f35a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"head\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "!head poetry.txt -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BC1cbnJRbwFx"
   },
   "source": [
    "***Задание*** Посчитайте частотности слов в файле за ```O(1)``` памяти, то есть без ```f.read()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.abspath(\"C://Users//Asus//ColingML//HW1//poetry.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1jJUv-BZbuRW",
    "outputId": "5725ee67-28f4-4efd-91fc-6d2c74c06a20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('и', 111567), ('в', 75623), ('не', 50963), ('я', 38550), ('на', 34623), ('как', 26493), ('с', 25614), ('что', 21918), ('ты', 18016), ('а', 16591), ('но', 15903), ('он', 14102), ('мне', 14093), ('за', 11356), ('то', 11194), ('все', 11147), ('к', 10751), ('по', 10471), ('о', 9791), ('мы', 9353), ('так', 8790), ('от', 8694), ('из', 8230), ('у', 7726), ('где', 7439), ('меня', 7081), ('когда', 6246), ('под', 6071), ('его', 5865), ('ни', 5818), ('нет', 5795), ('их', 5604), ('же', 5429), ('над', 5319), ('это', 5269), ('мой', 5182), ('кто', 5102), ('тебя', 5031), ('вот', 4929), ('да', 4727), ('только', 4712), ('она', 4693), ('без', 4652), ('до', 4568), ('там', 4502), ('бы', 4496), ('был', 4470), ('для', 4385), ('нам', 4073), ('нас', 3986), ('ли', 3889), ('всё', 3882), ('тебе', 3869), ('вы', 3743), ('во', 3714), ('ее', 3592), ('еще', 3575), ('сердце', 3547), ('чтоб', 3437), ('лишь', 3376), ('быть', 3216), ('жизнь', 3204), ('если', 3201), ('есть', 2963), ('они', 2881), ('может', 2760), ('было', 2753), ('день', 2737), ('здесь', 2707), ('моя', 2696), ('уж', 2615), ('твой', 2598), ('уже', 2550), ('жизни', 2543), ('пусть', 2525), ('со', 2523), ('любви', 2464), ('будет', 2447), ('ночь', 2418), ('чем', 2405), ('любовь', 2383), ('ж', 2377), ('всех', 2332), ('ней', 2294), ('вдруг', 2239), ('мир', 2238), ('б', 2187), ('ей', 2168), ('моей', 2164), ('тот', 2161), ('друг', 2102), ('или', 2102), ('теперь', 2095), ('вас', 2009), ('ему', 1997), ('хоть', 1955), ('тобой', 1949), ('ведь', 1935), ('опять', 1923), ('свой', 1898)]\n"
     ]
    }
   ],
   "source": [
    "word_counts = Counter()\n",
    "with open('poetry.txt', encoding='utf-8') as f:\n",
    "    text = \" \".join([l.lower().strip() for l in f])\n",
    "    text = re.sub('[^\\\\w\\\\s]',' ', text) \n",
    "    words = [word for word in text.split()]\n",
    "    word_counts.update(words)\n",
    "print(word_counts.most_common(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NB1HcZyNcTN1"
   },
   "source": [
    "Для создания нашей N-граммной модели будем накапливать статистику для всех строк стихотворений. \n",
    "Генерировать стихотворения будем построчно. Для этого нужно научить генерировать \"первое слово\" и \"последнее слово\" строки.\n",
    "\n",
    "**Задание** Напишите `parser` - функцию, которая будет выдавать поток токенов из файла. При этом каждая \"строка\" стихотворения должна начинаться с токена ```<BOS>``` и ```<EOS>```.\n",
    "Добавьте предобработку: фильтруйте все строки длиной менее 20 символов. Удалите все знаки препинания. Приведите к нижнему регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5IM9HOBEchqy"
   },
   "outputs": [],
   "source": [
    "def parser(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        all_tokens = []\n",
    "        for line in f:\n",
    "            if len(line) >= 20:\n",
    "                line = re.sub('[^\\w\\s]',' ', line.strip().lower())\n",
    "                line = \"<BOS> \" + line + \" <EOS>\"\n",
    "                words = line.split()\n",
    "                for w in words:\n",
    "                    yield w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse = parser(path)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sHKOg_mPdErP"
   },
   "source": [
    "Напишем N-граммную языковую модель по стишкам.\n",
    "\n",
    "Языковая модель умеет оценивать вероятности $\\mathbf{P}(w_1, \\ldots, w_n) = \\prod_k \\mathbf{P}(w_k|w_{k-1}, \\ldots, w_{1})$.\n",
    "\n",
    "N-граммная языковая модель приближает эту вероятность, используя предположение, что вероятность токена зависит только от недавней истории: $\\mathbf{P}(w_k|w_1, \\ldots, w_{k-1}) = \\mathbf{P}(w_k|w_{k-1}, \\ldots, w_{k-N + 1})$.\n",
    "\n",
    "Для начала нужно собрать статистику. Для простоты будем работать с биграмной моделью, а значит - нужно собрать информацию:\n",
    "\n",
    "- о биграммных частотностях $(w_{i-1}) \\to C(w_i)$\n",
    "- о триграммных частотностях $(w_{i-2}, w_{i-1}) \\to C(w_i)$\n",
    "\n",
    "Также хочется сохранять в статистику n-gram информацию о начале и коцне стишка.\n",
    "\n",
    "**Задание** Напишите функцию, которая будет из потока токенов формировать и выдавать наружу пары (ngram, next_word).\n",
    "\n",
    "Каждый стишок должен начинаться с токена ```<BOS>``` и заканчиваться ```<EOS>``` (beginning of sequence, end of sequence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uFd5wu12de8o"
   },
   "outputs": [],
   "source": [
    "\n",
    "def compose_ngram(tokens_stream):\n",
    "    \n",
    "    tokens = []\n",
    "    while True:\n",
    "        try:\n",
    "            token = next(tokens_stream)\n",
    "            tokens.append(token)\n",
    "            if token == \"<EOS>\":\n",
    "                tokens.append(\"<EOS>\")\n",
    "                pass\n",
    "                \n",
    "                try:\n",
    "                    for i in range(len(tokens)):\n",
    "                        yield (((tokens[i], tokens[i+1]), tokens[i+2]))\n",
    "                        yield (((tokens[i], tokens[i+1], tokens[i+2]), tokens[i+3]))\n",
    "                except IndexError:\n",
    "                    pass\n",
    "                        \n",
    "                \n",
    "                \n",
    "                \n",
    "                tokens = []\n",
    "                \n",
    "                \n",
    "        except StopIteration:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Подсказки:\n",
    "# Что сохраняем, если token --> <BOS>?\n",
    "# Что делаем, если token --> <EOS>?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pF3D8X4jis0r"
   },
   "source": [
    "Соберем статистику:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_counter = defaultdict(Counter)\n",
    "for ngram in compose_ngram(parse):\n",
    "    ngrams_counter[tuple(ngram[0])][ngram[1]] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdFzXmxLjJrk"
   },
   "source": [
    "Теперь генерировать будем так: есть стартовый токен. Проверяем последнюю триграмму в статистике. Если есть, генерируем с помощью нее новое слово. Если нет, ищем биграму (она должна быть).\n",
    "Если засемплили ```<EOS>``` --> завершаем генерацию и строку.\n",
    "Генерировать будем четверостишья (стихотворения из 4 строк)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "id": "cCy_cUEdnYLH"
   },
   "outputs": [],
   "source": [
    "def sample_token(ngrams_counter, ngram):\n",
    "    probs = np.array(list(ngrams_counter[ngram].values()))\n",
    "    probs = probs / np.sum(probs)\n",
    "    return np.random.choice(list(ngrams_counter[ngram]), p=probs)  \n",
    "  \n",
    "def generate_line(ngrams_counter):\n",
    "    \n",
    "    buffer = ['<BOS>']\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        initial_token = [ngram for ngram in ngrams_counter.keys() if len(ngram) == 3]\n",
    "        ind = np.random.choice(len(initial_token))\n",
    "        initial_token = initial_token[ind]\n",
    "        \n",
    "        if initial_token[2] != \"<EOS>\":\n",
    "            \n",
    "        \n",
    "            word = sample_token(ngrams_counter, initial_token)\n",
    "\n",
    "            if  \"<EOS>\" not in word:\n",
    "                buffer.append(word)\n",
    "                \n",
    "                \n",
    "                \n",
    "                new_token = (initial_token[1], initial_token[2], word)\n",
    "                \n",
    "                \n",
    "\n",
    "                if new_token in ngrams_counter:\n",
    "                    new_word = sample_token(ngrams_counter, new_token)\n",
    "                    if new_word == \"<EOS>\":\n",
    "                        break\n",
    "                    buffer.append(new_word)\n",
    "                    \n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                #else:\n",
    "                 #   new_token = (initial_token[2], word)\n",
    "                  #  new_word = sample_token(ngrams_counter, new_token)\n",
    "                   # if new_word == \"<EOS>\":\n",
    "                    #    break\n",
    "                    #buffer.append(new_word)\n",
    "                    \n",
    "            else:\n",
    "                    pass\n",
    "        else:\n",
    "            pass\n",
    "                    \n",
    "    buffer.append(\"<EOS>\")    \n",
    "    return (buffer)\n",
    "            \n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<BOS>',\n",
       " 'не',\n",
       " 'желаю',\n",
       " 'субботних',\n",
       " 'приложений',\n",
       " 'осеннего',\n",
       " 'бала',\n",
       " 'его',\n",
       " 'играя',\n",
       " 'перенесет',\n",
       " '<EOS>']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_line(ngrams_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Если брать еще и биграммы, то получается какая-то ерунда, поэтому пока оставлю как есть. Постараюсь придумать что-то получше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3XyqgnbLHK_",
    "outputId": "1bc720c4-8491-4a3e-cf42-e6085f9ba9e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "все крепчает но сколь заклятье\n",
      "тины водорослей и шумел ладонь\n",
      "легким скоком непрочен\n",
      "её уже старою курою в серсо громко и хочешь ты бурьена\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4):\n",
    "    print(' '.join(generate_line(ngrams_counter)).strip('<EOS> <BOS>'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "n-gram poroshok.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
